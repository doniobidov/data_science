{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5YrVmYIK8Lb"
      },
      "source": [
        "# Assignment 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC97H82OK8Lh"
      },
      "source": [
        "Please create a `data` folder and put all the datasets in the folder.\n",
        "\n",
        "In this assignment, you can use sklearn and other python libraries, if not explictly mentioned in the assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fnw--kk8K8Li"
      },
      "source": [
        "## Part-A: Regression - Polynomial Regression with Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVrHLtLmK8Li"
      },
      "source": [
        "1. (2 pts) Load the airfoil dataset and split the data into training and test datasets in ratio 80:20 using random splitting. \n",
        "2. (2 pts) Perform Z-score standardization on the data set. Hint: Please first derive the mean and std from the training dataset, and then apply the derived mean and std on the test dataset.\n",
        "3. (16 pts) Implement Polynomial regression with $l_2$ regularization on the airfoil dataset to predict \"Scaled sound pressure level\". Try different degrees and regularization parameters and compare the Mean Square Error (MSE) values. Select the best model using 5-fold cross-validation based on MSE. \n",
        "4. (5 pts) After selecting the best model, evaluate it on the test dataset.\n",
        "\n",
        "The dataset (dat file) is available on the Canvas Assignment page."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.linear_model import Ridge, LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "THIAqbeAf0iG"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWCJsX7XK8Lj",
        "outputId": "eea7b147-6033-4f8d-e686-aaba83e5530b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   frequency  Angle of attack  Chord length  Free-stream velocity  \\\n",
            "0        800              0.0        0.3048                  71.3   \n",
            "1       1000              0.0        0.3048                  71.3   \n",
            "2       1250              0.0        0.3048                  71.3   \n",
            "3       1600              0.0        0.3048                  71.3   \n",
            "4       2000              0.0        0.3048                  71.3   \n",
            "\n",
            "   Suction side displacement thickness  Scaled sound pressure level  \n",
            "0                             0.002663                      126.201  \n",
            "1                             0.002663                      125.201  \n",
            "2                             0.002663                      125.951  \n",
            "3                             0.002663                      127.591  \n",
            "4                             0.002663                      127.461  \n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"data/airfoil_self_noise.dat\",sep='\\t',names=['frequency','Angle of attack',\n",
        "                 'Chord length','Free-stream velocity','Suction side displacement thickness','Scaled sound pressure level'])\n",
        "print(df.head())\n",
        "\n",
        "# Your code here.\n",
        "X = df.iloc[:, :-1] # features\n",
        "y = df.iloc[:, -1] # response\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the training set\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# Standardize the test set\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "11CEN3TCf1VJ"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameters for grid search\n",
        "degrees = [1, 2, 3, 4, 5]\n",
        "alphas = [0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "# Create a pipeline\n",
        "pipe = Pipeline([('poly', PolynomialFeatures()), ('ridge', Ridge())])\n",
        "\n",
        "param = {'poly__degree': degrees, 'ridge__alpha': alphas}\n",
        "grid = GridSearchCV(pipe, param, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit to the training set\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Select the best model\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "print(f'Best model: {best_model}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMniVL1bj_g2",
        "outputId": "73ac3d9c-f004-4ae4-aae1-a492eda54f72"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model: Pipeline(steps=[('poly', PolynomialFeatures(degree=4)),\n",
            "                ('ridge', Ridge(alpha=0.01))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test on the test set\n",
        "y_hat = best_model.predict(X_test)\n",
        "test_mse = mean_squared_error(y_test, y_hat)\n",
        "\n",
        "print(f'Test MSE: {round(test_mse, 4)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cykmd6lff1Df",
        "outputId": "de8b5281-d3eb-4a52-d88d-4b278b653e69"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MSE: 12.3033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TO5Pc27K8Lk"
      },
      "source": [
        "## Part-B: Classification - KNN and Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IMHWPbWK8Ll"
      },
      "source": [
        "1. (2 pts) Load the the iris dataset and split the data into training and test datasets in ratio 80:20 using random splitting.\n",
        "2. (18 pts) Implement KNN algorithm without using sklearn. Try different K values (K=2, 5, 10, 20). Select the best model using 5-fold cross-validation based on accuracy and evaluate it on the test dataset. Report the test accuracy for each class and the overall test accuracy. Hint: matrix operations are much faster than for-loops!\n",
        "3. (10 pts) Train a Logistic Regression model on the iris dataset. Evaluate the model on the test data set. Report the test accuracy for each class and the overall test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "qI8POkiNK8Ll"
      },
      "outputs": [],
      "source": [
        "data = load_iris()\n",
        "\n",
        "# your code here\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the training set\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# Standardize the test set\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "yYON4zYEQGD9"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "Hq458UH1QjDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement KNN\n",
        "def knn(X_train, y_train, X_test, k):\n",
        "  m = X_test.shape[0] # number of test samples\n",
        "  n = X_train.shape[0] # number of train samples\n",
        "  y_hat = np.zeros(m) # initialize y_hat\n",
        "\n",
        "  # calculate Euclidean distance between each test sample and all train samples\n",
        "  for i in range(m):\n",
        "    dist = np.sqrt(np.sum((X_train - X_test[i])**2, axis=1))\n",
        "    # find k nearest neighbors\n",
        "    indx = np.argsort(dist)[:k]\n",
        "    k_label = y_train[indx]\n",
        "    # find the most common label\n",
        "    y_hat[i] = np.bincount(k_label).argmax() # index\n",
        "  \n",
        "  return y_hat"
      ],
      "metadata": {
        "id": "_1ooQQ2H0ADM"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for Grid Search CV\n",
        "def GS_CV(X, y, grid, cv=5):\n",
        "  best_k = None\n",
        "  best_score = 0\n",
        "\n",
        "  for k in grid:\n",
        "    scores = []\n",
        "    cross_valid = KFold(n_splits=cv, random_state=100, shuffle=True)\n",
        "    for tr_idx, val_idx in cross_valid.split(X):\n",
        "      X_tr, y_tr = X[tr_idx], y[tr_idx]\n",
        "      X_val, y_val = X[val_idx], y[val_idx]\n",
        "      y_predicted = knn(X_tr, y_tr, X_val, k)\n",
        "      scores.append(accuracy_score(y_val, y_predicted))\n",
        "    # Calculate average score for each k and return the best k\n",
        "    avg_score = np.mean(scores)\n",
        "    if avg_score > best_score:\n",
        "      best_k = k\n",
        "      best_score = avg_score\n",
        "\n",
        "  return (best_k, best_score)"
      ],
      "metadata": {
        "id": "bbssYtDNEjPY"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find best K using grid search CV\n",
        "grid = [2, 5, 10, 20]\n",
        "best_parameters = GS_CV(X_train, y_train, grid)\n",
        "best_k, best_score = best_parameters[0], best_parameters[1]\n",
        "print(f\"Best k: {best_k}\")\n",
        "print(f\"Best score: {best_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTzqj346Eo0T",
        "outputId": "29f732b3-34f8-488e-eff9-d200847ff009"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best k: 5\n",
            "Best score: 0.9583333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test on the test set\n",
        "y_hat = knn(X_train, y_train, X_test, best_k)\n",
        "test_accuracy = accuracy_score(y_test, y_hat)\n",
        "\n",
        "print(f'Overall test accuracy: {round(test_accuracy, 4)}')\n",
        "print(f'Accuracy for each class:\\n {classification_report(y_test, y_hat)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bcpgYncN1EE",
        "outputId": "26931bfa-0da1-4104-84c7-8188f7924530"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall test accuracy: 1.0\n",
            "Accuracy for each class:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        11\n",
            "           1       1.00      1.00      1.00         6\n",
            "           2       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "Gn6sIffQQsFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Logistic Regression\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_hat = lr.predict(X_test)\n",
        "\n",
        "# Test on the test set\n",
        "test_accuracy = accuracy_score(y_test, y_hat)\n",
        "class_accuracy = classification_report(y_test, y_hat)\n",
        "\n",
        "print(f'Overall test accuracy: {round(test_accuracy, 4)}')\n",
        "print(f'Accuracy for each class:\\n {class_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rolRCRDUVJTJ",
        "outputId": "eafb75bd-e974-471d-bd07-967dee7f384b"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall test accuracy: 0.9667\n",
            "Accuracy for each class:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        11\n",
            "           1       1.00      0.83      0.91         6\n",
            "           2       0.93      1.00      0.96        13\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.98      0.94      0.96        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR4iG5r4K8Lm"
      },
      "source": [
        "## Part-C: Classification - SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baJClA7RK8Ln"
      },
      "source": [
        "1. (2 pts) Load the australian dataset and split the data into training and test datasets in ratio 80:20.\n",
        "2. (18 pts) Use support vector machine (SVM) to predict whether a credit card should be approved for a person or not. Consider two different kernels and two different values of C. Select the best kernel using 5-fold cross validation. Evaluate the best model on the test dataset and report the accuracy.\n",
        "\n",
        "The dataset (dat file) is available on the Canvas Assignment page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "OCgC2zCkK8Ln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db0139b0-91f9-4af1-ce2f-b277bd5eb1f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   c1     c2     c3  c4  c5  c6     c7  c8  c9  c10  c11  c12  c13   c14  \\\n",
            "0   1  22.08  11.46   2   4   4  1.585   0   0    0    1    2  100  1213   \n",
            "1   0  22.67   7.00   2   8   4  0.165   0   0    0    0    2  160     1   \n",
            "2   0  29.58   1.75   1   4   4  1.250   0   0    0    1    2  280     1   \n",
            "3   0  21.67  11.50   1   5   3  0.000   1   1   11    1    2    0     1   \n",
            "4   1  20.17   8.17   2   6   4  1.960   1   1   14    0    2   60   159   \n",
            "\n",
            "   response  \n",
            "0         0  \n",
            "1         0  \n",
            "2         0  \n",
            "3         1  \n",
            "4         1  \n"
          ]
        }
      ],
      "source": [
        "df = pd.read_table(\"data/australian.dat\", sep=\" \", names=['c1','c2','c3','c4','c5','c6','c7','c8','c9','c10','c11','c12','c13','c14','response'])\n",
        "print(df.head())\n",
        "\n",
        "# Your code here.\n",
        "X = df.iloc[:, :-1] # features\n",
        "y = df.iloc[:, -1] # response\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the training set\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# Standardize the test set\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "2-UYtON_lWTu"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define SVM\n",
        "svm = SVC()\n",
        "\n",
        "# Define hyperparameters for the grid search\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'kernel': ['linear', 'poly', 'rbf']}\n",
        "\n",
        "# Define cross-validation\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=100)\n",
        "\n",
        "# Find the best model\n",
        "svm_grid_search = GridSearchCV(svm, param_grid=param_grid, cv=cv, n_jobs=-1)\n",
        "svm_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and the mean cross-validation score\n",
        "print(f'Best parameters: {svm_grid_search.best_params_}')\n",
        "print(f'Average CV score: {round(np.mean(svm_grid_search.best_score_), 4)}')\n",
        "\n",
        "# Select the best model\n",
        "best_svm = svm_grid_search.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoBB8ZM5bEcL",
        "outputId": "42511144-ba92-4993-e359-27961d778209"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'C': 0.01, 'kernel': 'linear'}\n",
            "Average CV score: 0.8551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the best SVM on the test set\n",
        "y_hat = best_svm.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_hat)\n",
        "print(f'Test accuracy of SVM: {round(accuracy, 4)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arn1vOAAihTT",
        "outputId": "d29a0b56-e93a-4ba2-b534-02100c310572"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy of SVM: 0.8623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOH44gniK8Lo"
      },
      "source": [
        "## Part-D: Classification - Ensembling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3mu-K3OK8Lo"
      },
      "source": [
        "We continue using the australian dataset.\n",
        "1. (5 pts) Train a KNN model on the dataset. Evaluate both models' performance on the test dataset. Report the test accuracy.\n",
        "2. (20 pts) Try two different ensemble methods on the dataset. Compare the performance of the ensemble models with the single model (KNN, SVM) and describe your observation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "ega44dHXK8Lo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89f68951-9d1b-4b82-f4cf-704f1080a69a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'n_neighbors': 7}\n",
            "Average CV score: 0.8551\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "# Define KNN\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Define hyperparameters for the grid search\n",
        "param_grid = {'n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15]}\n",
        "\n",
        "# Define cross-validation\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=100)\n",
        "\n",
        "# Find the best model\n",
        "knn_grid_search = GridSearchCV(knn, param_grid=param_grid, cv=cv, n_jobs=-1)\n",
        "knn_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and the mean cross-validation score\n",
        "print(f'Best parameters: {knn_grid_search.best_params_}')\n",
        "print(f'Average CV score: {round(np.mean(knn_grid_search.best_score_), 4)}')\n",
        "\n",
        "# Select the best model\n",
        "best_knn = knn_grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the best KNN on the test set\n",
        "y_hat = best_knn.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_hat)\n",
        "print(f'Test accuracy of KNN: {round(accuracy, 4)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrVYFvF8m59A",
        "outputId": "ba948906-3892-4327-8f61-3ec48a44136b"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy of KNN: 0.8768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ensemble models"
      ],
      "metadata": {
        "id": "GVZZ_v8NrSOx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Hard voting***"
      ],
      "metadata": {
        "id": "6F41Qd8dsiLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the voting classifier\n",
        "vote = VotingClassifier(estimators=[('svm', best_svm), ('knn', best_knn)], voting='hard')\n",
        "\n",
        "# Train the voting classifier\n",
        "vote.fit(X_train, y_train)\n",
        "\n",
        "# Test on the test set\n",
        "y_hat = vote.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_hat)\n",
        "print(f'Test accuracy of the Hard Vote Ensemble Model: {round(accuracy, 4)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jgCA1H8o9QI",
        "outputId": "071e9270-ca23-4dd7-ceef-1c9fbf7787f2"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy of the Hard Vote Ensemble Model: 0.8986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Stacked ensemble***"
      ],
      "metadata": {
        "id": "QufhYpQO8DQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the stacking classifier\n",
        "stack = StackingClassifier(estimators=[('svm', best_svm), ('knn', best_knn)], final_estimator=LogisticRegression())\n",
        "\n",
        "# Define hyperparameters for grid search to tune the final estimator\n",
        "parameters = {'final_estimator__C': [0.01, 0.1, 1, 10]}\n",
        "\n",
        "# Tune hyperparameters using 5-fold CV\n",
        "GS_CV = GridSearchCV(stack, parameters, cv=5)\n",
        "GS_CV.fit(X_train, y_train)\n",
        "\n",
        "# Select the best model\n",
        "best_logist = GS_CV.best_estimator_\n",
        "\n",
        "# Test on the test set\n",
        "y_hat = best_logist.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_hat)\n",
        "print(f'Test accuracy of the Stacked Ensemble Model: {round(accuracy, 4)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zn0QOz7jw3CF",
        "outputId": "7d1c8ad4-742d-4f80-bbef-fab798100bd5"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy of the Stacked Ensemble Model: 0.8623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Model | Test Accuracy |\n",
        "| -------- | -------- |\n",
        "| SVM | 0.86 |\n",
        "| KNN | 0.88 |\n",
        "| Majority Ensemble | 0.90 |\n",
        "| Stacked Ensemble | 0.86 |"
      ],
      "metadata": {
        "id": "ogpgvkFb6IrJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The majority vote ensemble model improved the overall accuracy on the test set. \n",
        "\n",
        "The stacked ensemble model performed worse than KNN and just as well as the SVM. This might be because I trained logistic regression for the final estimator model. Some other model could show a better performance."
      ],
      "metadata": {
        "id": "jPym1bhg7LuB"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}